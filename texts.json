{	
	"switch_lang" : {
		"en": "РУС/АНГЛ",
		"ru": "RU/EN"
	},
	"score": {
		"en": "Score",
		"ru": "Оценка"
	},
	"data": {
		"en": "Data",
		"ru": "Данные"
	},
	"nothing":{
		"en": "At least <b>one</b> Part of Speech must be selected!",
		"ru": "Должна быть выбрана хотя бы одна часть речи!"
	},
	"val_unfilt":{
		"en": "Values were not filtered by stopwords.",
		"ru":  "Значения без фильтрации по стоп-словам."
	}, 
	"key_unfilt":{
		"en": "Keys were not filtered by Part of Speech.",
		"ru":  "Ключи без фильтрации по части речи."
	}, 
	"tokens":{
		"en": "Tokens",
		"ru":  "Слова"
	}, 
	"classed":{
		"en": "classed as",
		"ru":  "класса"
	}, 
	"filt_keys":{
		"en": "were removed from keys.",
		"ru":  "были убраны из ключей."
	}, 
	"filt_vals":{
		"en": "were filtered out from values.",
		"ru":  "были убраны из значений."
	}, 
	"lim":{
		"en": "first items are shown.<br/>Download all data in JSON or CSV format.",
		"ru":  "первых элементов отображены.<br/>Данные в полном виде можно скачать в формате JSON или CSV."
	}, 
	"btn_desc": {
		"en": "Description",
		"ru": "Описание"
	},
	"btn_res": {
		"en": "Results",
		"ru": "Результаты"
	},
	"icon": {
		"en": "The site icon by",
		"ru": "Значок сайта от"
	},
	"graph":{
		"en": "Mean accuracy in prediction of models",
		"ru": "Средняя точность в предсказаниях моделей"	
	},
	"NOUNS": {
		"en": "noun",
		"ru": "имя существительное"
	},
	"VERBS": {
		"en": "verb",
		"ru": "глагол"
	},
	"ADJECTIVES": {
		"en": "adjective",
		"ru": "имя прилагательное"
	},
	"ADVERBS": {
		"en": "adverb",
		"ru": "наречие"
	},

	"nn": {
		"en": "nouns",
		"ru": "сущ."
	},
	"vb": {
		"en": "verbs",
		"ru": "глаголы"
	},
	"aj": {
		"en": "adjectives",
		"ru": "прил."
	},
	"av": {
		"en": "adverbs",
		"ru": "наречия"
	},
	"stops": {
		"en": "Stopwords in results (values). Check to <b>ex</b>clude",
		"ru": "Стоп-слова в результатах (значения). <b>Не</b>&nbsp;показывать, если выбрано" 
	},
	"stops_tip": {
		"en": "Put additional tokens to filter (comma separated)",
		"ru": "Можно добавить слова для фильтрации (разделитель – запятая)" 
	},
	"pos": {
		"en": "Parts of speech (keys). Check to <b>in</b>clude",
		"ru": "Части речи (ключи). Показывать выбранные" 
	},
	"table": {
		"en": ["key", "class", "token", "probability"],
		"ru": ["ключ", "класс", "токен", "вероятность"]
	},
	"footer1": {
		"en": "The work was done in terms of the",
		"ru": "Проект выполнен в рамках"
	},
	"footer_link": {
		"en": "Master Program in Computational Linguistics",
		"ru": "МП «Компьютерная лингвистика»"
	},
	"footer2": {
		"en": "at the National Research University Higher School of Economics, Moscow",
		"ru": "в НИУ ВШЭ, Москва"
	},

	"run": {
		"en": "Run Python Notebook",
		"ru": "Перейти к тетради Python"
	},
	"load": {
		"en": "Download as",
		"ru": "Загрузить в формате"
	},
	"cust": {
		"en": "Data download customization",
		"ru": "Выбор данных для загрузки"
	},
	"title": {
		"ru": "Предсказуемость",
		"en": "Predictability"
	},
	"about": {
		"ru": "О проекте",
		"en": "About the project"
	},
	"project": {
		"ru": ["Термин, который дал название данному проекту, является одним из ключевых в области понимания языка. В когнитивной лингвистике под ним подразумевается степень уверенности в том, какая языковая единица (слово, часть речи и т.п.) будет следовать дальше в предложении (тексте). Это свойство токена в контексте обычно измеряют в вероятностных единицах и приписывают ему наличие некоторых общеизвестных свойств. Например, подразумевается, что сумма вероятностей всех слов, которыми можно продолжить левый контекст, равна единице. Эти предположения в свое время положили начало работам над искусственными языковыми моделями (ИЯМ). ", "Исследовательские работы в области когнитивной науки показали, что при чтении предложения правильно предсказанное следующее слово упрощает восприятие языковой единицы и ее интеграцию в контекст. Неправильное предсказание может повлечь за собой необходимость в повторном анализе контекста, то есть языковая обработка замедляется. Характер зависимости между этими двумя фактами, однако, до сих пор не установлен.", "В современных лингвистических и когнитивных исследованиях в качестве методов для получения данных о вероятностном распределении лексических единиц для конкретного контекста используются искусственные языковые модели различных архитектур или cloze test. Последний подвергается критике по причине недостаточного охвата, однако менее именно он использует “человеческие” языковые механизмы генерации речи в отличие от ИЯМ, которые представляют собой набор различных математических алгоритмов, примененных к корпусу текстов. Сравнению двух этих типов методов посвящен данный проект."],
		"en": ["The term that gave the name to this project is one of the key terms in natural language understanding. In cognitive linguistics, it implies a confidence degree of a language unit (word, part of speech, etc.) that can take next place in the sentence (or text). This property of the token in the context is usually measured in terms of the theory of probability, and it also has some well-known probabilistic properties. For example, the sum of the probabilities of all words which can or cannot (in terms of common sense) “continue” the left context is equal to one. A quarter-century ago these assumptions led to the emergence of the first artificial language models (ALM).", "Research papers in the field of cognitive science have shown that correct prediction of the next word while reading a sentence simplifies the perception of a language unit and its integration into the context. Incorrect prediction can lead to re-analysis of the context which is why language processing is slowed down. However, the types of dependencies between these two facts are still not well studied.", "Nowadays, in linguistic and cognitive studies, to obtain data describing the probabilistic distribution of lexical units (for a specific context), artificial language models of various architectures are used or cloze tests are conducted on real-life participants. The last one is frequently criticized for lack of coverage. Nevertheless, in terms of common sense, it is a cloze test, which uses the so-called “human” linguistic mechanisms of speech generation to collect the data. The ALM, in contrast, is basically a set of various mathematical algorithms applied to the text corpus. This project is aimed to compare these two types of methods."]
	},
	"res": {
		"ru": "О результатах",
		"en": "Results"
	},
	"meta": {
		"ru": "Методология",
		"en": "Methodology"
	},
	"meta_desc": {
		"ru": "Одним из важных результатов нашего исследования является разработка набора методов (инструментов) для сравнения генеративных свойств языковых моделей. Начальной точкой является неограниченный набор контекстов и вероятностных распределении слов к ним. Мы опробовали нашу методику на следующих моделях: cloze test модель, скрытые марковские цепи (на разных длинах н-грамм), LSTM, BERT. Обучение ИЯМ производилось на разных корпусах, что позволило отразить и жанрово-стилистические особенности корпусов в результирующих моделях. Важным инструментов исследования является язык программирования Python, на котором были имплементированы все сравнительные метрики. Ознакомиться с кодом и результатами Вы можете по ссылке ниже. Архитектура имплементации позволяет добавлять новые модели, а детерминированность алгоритмов отражает неизменность результата.",
		"en": "One of the important results of our study is the development of a certain set of methods (tools) for comparing the generative properties of language models. The starting point is an unrestricted set of contexts and the probabilistic distribution of words for each of them. We tested our methodology on the following models: cloze-test-based model, hidden Markov model (with the different n-grams), LSTM, BERT. The training on different corpora allows us to reflect the genre and stylistic features of the original texts in the resulting models. An important research tool is the Python programming language, in which all comparative metrics were implemented. You can study the data with code and the results at the link below. The implementation architecture allows adding new models, and the determinism of the algorithms reflects the constancy of the result."
	},
	"sel": {
		"ru": "Избранные материалы",
		"en": "Pre-selected materials"
	},
	"sel_desc": {
		"ru": "Результаты исследований показали, что если принять модель cloze test в качестве базовой (то есть отражающей свойства и особенности порождения речи человеком)  и считать ее результаты наиболее правдоподобными, то самыми близкими к ней по значениям метрик являются  скрытая марковская модель и BERT. Ниже приведена таблица, построенная на базе дивергенции Кульбака-Лейблера для контекстов разной длины. Результаты показали, что на коротких контекстах лучше работает скрытая марковская модель, а на длинных - BERT. Кроме того, мы экспериментировали с разнообразными контекстами длиной 1 токен (наиболее частотные слова самостоятельных частей речи – существительные, прилагательные, глаголы, наречия, – выбранные с помощью НКРЯ).  Ни одна из существующих предобученных ИЯМ не показывает в таких условиях высокого качества, то есть ИЯМ не генерируют короткие устойчивые выражения (частотные биграммы) в бесконтекстных условиях. Поэтому мы предоставляем корпус, отражающий частотную модель на базе НКРЯ; он может быть использован в образовательных целях, для подготовки курсах русского языка для иностранцев.",
		"en": "The research results showed that if we accept the cloze test model as the basic one (i.e. it obtains the property of human speech generation model) and consider its results the most plausible, then the most similar models (according to our metric results)  are hidden Markov model (HMM) and BERT. The table below is based on the Kullback-Leibler divergence for contexts of different lengths. According to the results, while HMM works better on short texts, BERT shows higher results on long ones. In addition, we experimented on specific contexts (the most frequent words which belong to open classes – nouns, verbs, adjectives, adverbs – selected with the help of NCRL) of length 1. None of the existing pre-trained ALMs show high quality, i.e. ALMs do not generate collocations (frequent bigrams) in contextless conditions. Therefore, we provide a corpus reflecting the frequency model based on NCRL which can be useful for educational purposes in Russian language courses for foreign students."
	}
}